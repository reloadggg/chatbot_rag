from fastapi import FastAPI, Query, UploadFile, File, HTTPException, Form, Depends, Header, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, JSONResponse
from pydantic import BaseModel
from app.settings import settings, print_env_status
from app.rag import rag_pipeline
from app.document_processor import document_processor
from app.gemini_routes import router as gemini_router
from app.auth import auth_manager
from app.user_config import user_config_manager, UserConfig
import json
import asyncio
from typing import Any, Dict, List, Optional
from pathlib import Path

app = FastAPI(title=settings.app_name)

# CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.allow_origins.split(","),
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class QueryRequest(BaseModel):
    question: str

class DocumentInfo(BaseModel):
    file_id: str
    filename: str
    file_size: int
    created_at: float
    text_length: Optional[int] = None
    chunks_count: Optional[int] = None
    status: str

class LoginRequest(BaseModel):
    password: str
    provider: str = "env"  # env, openai, gemini

class GuestLoginRequest(BaseModel):
    llm_provider: str
    llm_model: str
    llm_api_key: str
    llm_base_url: Optional[str] = None
    embedding_provider: str
    embedding_model: str
    embedding_api_key: str
    embedding_base_url: Optional[str] = None

class AuthResponse(BaseModel):
    access_token: str
    token_type: str
    user_type: str
    config: Dict[str, Any]
    providers: Dict[str, Any]

# ä¾èµ–å‡½æ•°
def get_current_user(authorization: Optional[str] = Header(None)) -> Dict[str, Any]:
    """è·å–å½“å‰ç”¨æˆ·"""
    if not authorization:
        raise HTTPException(status_code=401, detail="æœªæä¾›è®¤è¯ä¿¡æ¯")
    
    try:
        # æå–Bearer token
        scheme, token = authorization.split()
        if scheme.lower() != "bearer":
            raise HTTPException(status_code=401, detail="æ— æ•ˆçš„è®¤è¯æ–¹æ¡ˆ")
        
        # éªŒè¯token
        token_data = auth_manager.verify_token(token)
        if not token_data:
            raise HTTPException(status_code=401, detail="æ— æ•ˆçš„è®¤è¯ä»¤ç‰Œ")
        
        return token_data
    except Exception:
        raise HTTPException(status_code=401, detail="è®¤è¯å¤±è´¥")

def get_user_config(current_user: Dict[str, Any] = Depends(get_current_user)) -> Dict[str, Any]:
    """è·å–ç”¨æˆ·é…ç½®"""
    return auth_manager.get_user_api_config(current_user)

def get_current_user_optional(authorization: Optional[str] = Header(None)) -> Optional[Dict[str, Any]]:
    """å°½é‡è·å–å½“å‰ç”¨æˆ·ï¼Œå¤±è´¥è¿”å›None"""
    if not authorization:
        return None
    try:
        scheme, token = authorization.split()
        if scheme.lower() != "bearer":
            return None
        return auth_manager.verify_token(token)
    except Exception:
        return None

def get_current_user_optional(authorization: Optional[str] = Header(None)) -> Optional[Dict[str, Any]]:
    if not authorization:
        return None
    try:
        scheme, token = authorization.split()
        if scheme.lower() != "bearer":
            return None
        return auth_manager.verify_token(token)
    except Exception:
        return None

# ===== è®¤è¯ç›¸å…³API =====

@app.post("/auth/login", response_model=AuthResponse)
async def login(request: LoginRequest):
    """ç”¨æˆ·ç™»å½•"""
    try:
        # éªŒè¯ç³»ç»Ÿå¯†ç 
        if auth_manager.validate_system_password(request.password):
            # åˆ›å»ºç³»ç»Ÿç”¨æˆ·ä»¤ç‰Œ
            access_token = auth_manager.create_system_token()
            
            # è·å–ç³»ç»Ÿé…ç½®
            system_config = auth_manager.get_user_api_config({
                "user_type": "system",
                "provider": request.provider
            })
            
            return AuthResponse(
                access_token=access_token,
                token_type="bearer",
                user_type="system",
                config=system_config,
                providers={
                    "llm_providers": [
                        {
                            "name": "openai",
                            "models": ["gpt-4o-mini", "gpt-4o"],
                            "available": bool(system_config.get("llm_api_key"))
                        }
                    ],
                    "embedding_providers": [
                        {
                            "name": "openai",
                            "models": ["text-embedding-3-small"],
                            "available": bool(system_config.get("embedding_api_key"))
                        }
                    ]
                }
            )
        else:
            raise HTTPException(status_code=401, detail="å¯†ç é”™è¯¯")
            
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ ç™»å½•å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail="ç™»å½•å¤±è´¥")

@app.post("/auth/guest", response_model=AuthResponse)
async def guest_login(request: GuestLoginRequest):
    """æ¸¸å®¢ç™»å½•"""
    try:
        # éªŒè¯æ¸¸å®¢é…ç½®
        config_data = request.dict()
        errors = user_config_manager.validate_provider_config(config_data)
        
        if errors:
            raise HTTPException(status_code=400, detail=f"é…ç½®éªŒè¯å¤±è´¥: {errors}")
        
        # åˆ›å»ºæ¸¸å®¢ä¼šè¯
        import uuid
        session_id = str(uuid.uuid4())
        
        # åˆ›å»ºæ¸¸å®¢é…ç½®
        guest_config = user_config_manager.create_user_config(config_data)
        
        # åˆ›å»ºæ¸¸å®¢ä»¤ç‰Œ
        access_token = auth_manager.create_guest_token(session_id, guest_config.__dict__)
        
        # è·å–æä¾›å•†ä¿¡æ¯
        providers_info = {
            "llm_providers": [
                {
                    "name": "openai",
                    "models": ["gpt-4o-mini", "gpt-4o"],
                    "available": guest_config.llm_provider == "openai" and bool(guest_config.llm_api_key)
                },
                {
                    "name": "gemini",
                    "models": ["gemini-2.0-flash-exp", "gemini-1.5-flash"],
                    "available": guest_config.llm_provider == "gemini" and bool(guest_config.llm_api_key)
                }
            ],
            "embedding_providers": [
                {
                    "name": "openai",
                    "models": ["text-embedding-3-small"],
                    "available": guest_config.embedding_provider == "openai" and bool(guest_config.embedding_api_key)
                },
                {
                    "name": "gemini",
                    "models": ["models/embedding-001"],
                    "available": guest_config.embedding_provider == "gemini" and bool(guest_config.embedding_api_key)
                }
            ]
        }
        
        return AuthResponse(
            access_token=access_token,
            token_type="bearer",
            user_type="guest",
            config=guest_config.__dict__,
            providers=providers_info
        )
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ æ¸¸å®¢ç™»å½•å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail="æ¸¸å®¢ç™»å½•å¤±è´¥")

@app.get("/auth/config")
async def get_auth_config(current_user: Dict[str, Any] = Depends(get_current_user)):
    """è·å–å½“å‰ç”¨æˆ·çš„APIé…ç½®"""
    try:
        config = auth_manager.get_user_api_config(current_user)
        return {
            "user_type": current_user.get("user_type"),
            "config": config,
            "providers": {
                "llm_providers": [
                    {
                        "name": "openai",
                        "models": ["gpt-4o-mini", "gpt-4o"],
                        "available": bool(config.get("llm_api_key"))
                    },
                    {
                        "name": "gemini",
                        "models": ["gemini-2.0-flash-exp", "gemini-1.5-flash"],
                        "available": bool(config.get("llm_api_key"))
                    }
                ],
                "embedding_providers": [
                    {
                        "name": "openai",
                        "models": ["text-embedding-3-small"],
                        "available": bool(config.get("embedding_api_key"))
                    },
                    {
                        "name": "gemini",
                        "models": ["models/embedding-001"],
                        "available": bool(config.get("embedding_api_key"))
                    }
                ]
            }
        }
    except Exception as e:
        print(f"âŒ è·å–ç”¨æˆ·é…ç½®å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail="è·å–ç”¨æˆ·é…ç½®å¤±è´¥")

@app.get("/auth/status")
async def get_auth_status():
    """è·å–è®¤è¯ç³»ç»ŸçŠ¶æ€"""
    return {
        "system_mode_enabled": auth_manager.is_system_mode_enabled(),
        "auth_required": True,  # æ€»æ˜¯éœ€è¦è®¤è¯
        "supported_modes": ["system", "guest"]
    }

@app.get("/providers")
async def get_providers(current_user: Optional[Dict[str, Any]] = Depends(get_current_user_optional)):
    """è·å–AIæä¾›å•†ä¿¡æ¯ï¼ˆæ¸¸å®¢å¯è®¿é—®ï¼‰"""
    try:
        base_config = auth_manager.get_user_api_config(current_user or {"user_type": "guest"})
        return {
            "llm_providers": [
                {
                    "name": "openai",
                    "models": ["gpt-4o-mini", "gpt-4o"],
                    "available": bool(base_config.get("llm_api_key"))
                },
                {
                    "name": "gemini",
                    "models": ["gemini-2.0-flash-exp", "gemini-1.5-flash"],
                    "available": bool(base_config.get("llm_api_key"))
                }
            ],
            "embedding_providers": [
                {
                    "name": "openai",
                    "models": ["text-embedding-3-small"],
                    "available": bool(base_config.get("embedding_api_key"))
                },
                {
                    "name": "gemini",
                    "models": ["models/embedding-001"],
                    "available": bool(base_config.get("embedding_api_key"))
                }
            ],
            "current_config": {
                "llm_provider": base_config.get("llm_provider"),
                "llm_model": base_config.get("llm_model"),
                "embedding_provider": base_config.get("embedding_provider"),
                "embedding_model": base_config.get("embedding_model"),
            }
        }
    except Exception as e:
        print(f"âŒ è·å–æä¾›å•†ä¿¡æ¯å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail="è·å–æä¾›å•†ä¿¡æ¯å¤±è´¥")

# ===== å—ä¿æŠ¤çš„APIï¼ˆéœ€è¦è®¤è¯ï¼‰ =====

@app.get("/healthz", dependencies=[Depends(get_current_user)])
async def health_check(current_user: Dict[str, Any] = Depends(get_current_user)):
    """ç³»ç»Ÿå¥åº·æ£€æŸ¥ï¼ˆéœ€è¦è®¤è¯ï¼‰"""
    return {
        "status": "ok",
        "env": settings.env,
        "embedding_model": settings.embedding_model,
        "llm_model": settings.llm_model,
        "message": "ç³»ç»Ÿè¿è¡Œæ­£å¸¸",
        "user_type": current_user.get("user_type"),
        "providers": {
            "llm": settings.llm_provider,
            "embedding": settings.embedding_provider,
            "gemini_available": rag_pipeline.is_gemini_available()
        }
    }

@app.post("/query", dependencies=[Depends(get_current_user)])
async def query_once(
    request: QueryRequest,
    current_user: Dict[str, Any] = Depends(get_current_user),
    user_config: Dict[str, Any] = Depends(get_user_config)
):
    """å•æ¬¡æŸ¥è¯¢ï¼ˆéœ€è¦è®¤è¯ï¼‰"""
    try:
        # ä½¿ç”¨ç”¨æˆ·çš„é…ç½®åˆ›å»ºRAGå®ä¾‹
        # è¿™é‡Œéœ€è¦åŠ¨æ€åˆ›å»ºRAGå®ä¾‹ï¼Œè€Œä¸æ˜¯ä½¿ç”¨å…¨å±€å®ä¾‹
        # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬æš‚æ—¶ä½¿ç”¨å…¨å±€é…ç½®ï¼Œåç»­å¯ä»¥ä¼˜åŒ–
        answer = rag_pipeline.query(request.question)
        return {
            "question": request.question,
            "answer": answer,
            "status": "success",
            "provider": rag_pipeline.provider or settings.llm_provider,
            "user_type": current_user.get("user_type")
        }
    except Exception as e:
        return {
            "question": request.question,
            "answer": f"å¤„ç†é—®é¢˜æ—¶å‡ºç°é”™è¯¯: {str(e)}",
            "status": "error",
            "user_type": current_user.get("user_type")
        }

@app.get("/stream", dependencies=[Depends(get_current_user)])
async def stream_query(
    question: str = Query(...),
    current_user: Dict[str, Any] = Depends(get_current_user),
    user_config: Dict[str, Any] = Depends(get_user_config)
):
    """æµå¼æŸ¥è¯¢ï¼ˆéœ€è¦è®¤è¯ï¼‰"""
    async def generate():
        try:
            for chunk in rag_pipeline.stream_query(question):
                yield f"data: {json.dumps({'chunk': chunk}, ensure_ascii=False)}\n\n"
                await asyncio.sleep(0.01)  # å°å»¶è¿Ÿç¡®ä¿æµå¼æ•ˆæœ
            yield f"data: {json.dumps({'status': 'done'}, ensure_ascii=False)}\n\n"
        except Exception as e:
            yield f"data: {json.dumps({'error': str(e)}, ensure_ascii=False)}\n\n"
    
    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )

# ===== æ–‡ä»¶ä¸Šä¼ å’Œç®¡ç†APIï¼ˆéœ€è¦è®¤è¯ï¼‰ =====

@app.post("/upload", dependencies=[Depends(get_current_user)])
async def upload_file(
    file: UploadFile = File(...),
    description: Optional[str] = Form(None),
    process: bool = Form(True),
    current_user: Dict[str, Any] = Depends(get_current_user),
    user_config: Dict[str, Any] = Depends(get_user_config)
):
    """ä¸Šä¼ æ–‡ä»¶åˆ°çŸ¥è¯†åº“ï¼ˆéœ€è¦è®¤è¯ï¼‰"""
    try:
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        allowed_extensions = {'.pdf', '.txt', '.md', '.json'}
        file_extension = Path(file.filename).suffix.lower()
        
        if file_extension not in allowed_extensions:
            raise HTTPException(
                status_code=400, 
                detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ã€‚æ”¯æŒçš„ç±»å‹: {', '.join(allowed_extensions)}"
            )
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å° (æœ€å¤§10MB)
        file_content = await file.read()
        if len(file_content) > 10 * 1024 * 1024:
            raise HTTPException(
                status_code=400, 
                detail="æ–‡ä»¶å¤§å°è¶…è¿‡10MBé™åˆ¶"
            )
        
        print(f"ğŸ“¤ æ­£åœ¨ä¸Šä¼ æ–‡ä»¶: {file.filename}")
        
        # å¤„ç†æ–‡ä»¶
        result = document_processor.process_file(
            file_content, 
            file.filename,
            {"description": description} if description else {}
        )
        
        if result["status"] == "error":
            raise HTTPException(status_code=500, detail=result["error"])
        
        # å¦‚æœè¦æ±‚å¤„ç†ï¼Œæ·»åŠ åˆ°å‘é‡æ•°æ®åº“
        if process and result["chunks"]:
            success = rag_pipeline.add_documents(result["chunks"])
            if success:
                print(f"âœ… æ–‡ä»¶å·²æ·»åŠ åˆ°çŸ¥è¯†åº“: {file.filename}")
            else:
                print(f"âš ï¸  æ–‡ä»¶æ·»åŠ åˆ°çŸ¥è¯†åº“å¤±è´¥: {file.filename}")
        
        return {
            "message": "æ–‡ä»¶ä¸Šä¼ æˆåŠŸ",
            "file_id": result["file_id"],
            "filename": result["filename"],
            "text_length": result["text_length"],
            "chunks_count": result["chunks_count"],
            "processed": process,
            "status": "success",
            "provider": rag_pipeline.provider or settings.llm_provider,
            "user_type": current_user.get("user_type")
        }
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}")

# æ·»åŠ Geminiè·¯ç”±ï¼ˆä¹Ÿéœ€è¦è®¤è¯ï¼‰
app.include_router(gemini_router, dependencies=[Depends(get_current_user)])

# æ·»åŠ Pathå¯¼å…¥
from pathlib import Path

if __name__ == "__main__":
    print_env_status()
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=settings.port)
